(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{450:function(t,s,r){"use strict";r.r(s);var v=r(2),a=Object(v.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"试列出至少三种目前流行的大型数据库"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#试列出至少三种目前流行的大型数据库"}},[t._v("#")]),t._v(" 试列出至少三种目前流行的大型数据库")]),t._v(" "),s("p",[t._v("Oracle MySQL SQLserver")]),t._v(" "),s("h2",{attrs:{id:"列举您使用过的python网络爬虫所用到的网络数据包"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#列举您使用过的python网络爬虫所用到的网络数据包"}},[t._v("#")]),t._v(" 列举您使用过的Python网络爬虫所用到的网络数据包?")]),t._v(" "),s("p",[t._v("requests, urllib,urllib2, httplib2")]),t._v(" "),s("p",[t._v("urllib 和urllib2模块都做与请求URL相关的操作，但他们提供不同的功能。urllib2.urlopen可以接受一个Request对象或者url,(在接受Request对象时，并以此可以来设置一个URL的headers),urllib.urlopen只接收一个url。")]),t._v(" "),s("p",[t._v("scrapy是封装起来的框架，他包含了下载器，解析器，日志及异常处理，基于多线程，twisted的方式处理，对于固定单个网站的爬取开发，有优势，但是对于多网站爬取100个网站，并发及分布式处理不够灵活，不便调整与扩展。Scrapy优点：异步，xpath，强大的统计和log系统，支持不同url。shell方便独立调试。写middleware方便过滤。通过管道存入数据库")]),t._v(" "),s("p",[t._v("requests是一个HTTP库，它只是用来请求，它是一个强大的库，下载，解析全部自己处理，灵活性高。")]),t._v(" "),s("h2",{attrs:{id:"写爬虫是用多进程好-还是多线程好"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#写爬虫是用多进程好-还是多线程好"}},[t._v("#")]),t._v(" 写爬虫是用多进程好？还是多线程好？")]),t._v(" "),s("p",[t._v("在爬虫中，请求的并发业务属于是网络的IO类型业务，因此网络并发适宜使用多线程。")]),t._v(" "),s("h2",{attrs:{id:"常见的反爬虫和应对方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常见的反爬虫和应对方法"}},[t._v("#")]),t._v(" 常见的反爬虫和应对方法？")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("User-Agent检测")]),t._v("，网站可能会检查请求的 User-Agent 字段，如果发现是自动化爬虫，就会拒绝服务或返回错误页面。\n"),s("strong",[t._v("应对方法")]),t._v("：设置合适的 User-Agent 字段，使其看起来像是普通浏览器发送的请求，例如使用真实浏览器的 User-Agent 信息，或者选择通用的、不太容易被识别为爬虫的 User-Agent。")]),t._v(" "),s("li",[s("strong",[t._v("IP封锁/频率限制")]),t._v("，网站可能会监控某个IP地址的请求频率，如果请求过于频繁，可能会封禁IP或者返回验证码页面。\n"),s("strong",[t._v("应对方法")]),t._v("：使用代理IP：轮换多个IP地址发送请求，避免单个IP请求频率过高。\n控制请求频率：通过在爬虫中设置延迟时间、随机化请求间隔等方式来模拟人类的行为。")]),t._v(" "),s("li",[s("strong",[t._v("验证码")]),t._v("，网站可能会在访问频繁或者请求过多时要求输入验证码，以确认请求来自真实用户。\n"),s("strong",[t._v("应对方法")]),t._v("：手动处理验证码：对于少量的验证码，可以手动处理；对于大量的验证码，可能需要使用验证码识别服务（OCR）来自动处理。\n限制访问频率：降低请求频率，以减少触发验证码的可能性。")]),t._v(" "),s("li",[s("strong",[t._v("动态加载和JavaScript渲染")]),t._v("，网站可能会使用JavaScript动态加载内容，这样爬虫可能无法直接获取到全部数据。\n"),s("strong",[t._v("应对方法")]),t._v("：使用Headless浏览器：如Selenium等工具可以模拟浏览器行为，执行JavaScript并获取动态加载的内容；分析API：有些网站可能有公开的API，可以直接获取数据，避免页面渲染的问题。")]),t._v(" "),s("li",[s("strong",[t._v("随机化和伪装")]),t._v("，网站可能会检查爬取行为的模式，包括请求路径、参数等。\n"),s("strong",[t._v("应对方法")]),t._v("：随机化请求路径和参数：在请求时随机生成一些路径或参数，使请求看起来更随机化；使用多个账号登录：有些网站可能会根据账号的使用模式来检测爬虫行为，使用多个账号轮换请求可以减少风险。")]),t._v(" "),s("li",[s("strong",[t._v("数据分析和模式识别")]),t._v("，网站可能会根据特定的模式识别爬虫行为，如请求频率、访问路径等。\n"),s("strong",[t._v("应对方法")]),t._v("：模拟人类行为：尽量模拟人类的行为方式，包括随机化请求间隔、随机化访问路径等；数据混淆和噪声：在爬取数据中加入一些噪声或混淆，使数据看起来更加随机化和自然")])]),t._v(" "),s("h2",{attrs:{id:"解析网页的解析器使用最多的是哪几个"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#解析网页的解析器使用最多的是哪几个"}},[t._v("#")]),t._v(" 解析网页的解析器使用最多的是哪几个?")]),t._v(" "),s("p",[t._v("BeautifulSoup XPath CSS选择器")]),t._v(" "),s("p",[t._v("BeautifulSoup 是一个灵活且易于使用的库，可以解析HTML和XML文档。它提供了便捷的方法来遍历文档树、搜索特定元素和提取信息。")]),t._v(" "),s("p",[t._v("XPath 是一种在XML文档中查找信息的语言，可以通过路径表达式在XML文档中选取节点。")]),t._v(" "),s("h2",{attrs:{id:"需要登录的网页-如何解决同时限制ip-cookie-session"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#需要登录的网页-如何解决同时限制ip-cookie-session"}},[t._v("#")]),t._v(" 需要登录的网页，如何解决同时限制ip，cookie，session？")]),t._v(" "),s("p",[t._v("解决限制IP可以使用代理IP地址池、服务器；不适用动态爬取的情况下可以使用反编译JS文件获取相应的文件，或者换用其它平台（比如手机端）看看是否可以获取相应的json文件。")]),t._v(" "),s("h2",{attrs:{id:"验证码的解决"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#验证码的解决"}},[t._v("#")]),t._v(" 验证码的解决？")]),t._v(" "),s("ol",[s("li",[t._v("输入式验证码\n使用OCR识别，将验证图转化成灰度图、去背景噪声。")])])])}),[],!1,null,null,null);s.default=a.exports}}]);